Metadata-Version: 2.1
Name: doc-search
Version: 1.0.7
Summary: A package for searching documentation built with sphinx
Home-page: https://github.com/Tom-the-Bomb/doc-search
Author: Tom-the-Bomb
License: MIT
Project-URL: Repository, https://github.com/Tom-the-Bomb/doc-search
Project-URL: Issue tracker, https://github.com/Tom-the-Bomb/doc-search/issues
Platform: UNKNOWN
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Utilities
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: aiohttp
Requires-Dist: requests

# Doc-search
A simple package for searching documentation

**Features**
- Both async and sync support
- utilizes a cache to limit the number of requests being made
- works for any documentation that is built with sphinx

### Example

**asyncio**
```py
import asyncio
from doc_search import AsyncScraper

scraper = AsyncScraper()

async def main(query):
    results = await scraper.search(query, page="https://docs.python.org/3/")
    #returns a list of tuples in the format of [(item, url), (item, url)...]
    if not results:
        print("no results were found")
    else:
        for item, url in results:    #loop through the list of results
            print(f"{item} | {url}") #print out each result

asyncio.run(main("str.split"))

# to view the cache
# print(scraper.cache)
```

**sync**
```py
from doc_search import SyncScraper

scraper = SyncScraper()
results = scraper.search("resize", page="https://pillow.readthedocs.io/en/stable/")
if not results:
    print("no results were found")
else:
    for item, url in results:    #loop through the list of results
        print(f"{item} | {url}") #print out each result
```

### Beta

- Offers searches for **C** and **C++** docs using the `scraper.search_c` and `scraper.search_cpp` methods
    **EX:** 
    ```py
    scraper = SyncScraper()
    results = scraper.search_c("printf")
    ```

